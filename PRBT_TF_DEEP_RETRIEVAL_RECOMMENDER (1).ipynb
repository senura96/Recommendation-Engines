{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qT0EqpYOsHMf",
        "outputId": "631d1b56-e802-49f7-d7a1-ad866459107d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/96.2 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.2/96.2 KB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q tensorflow-recommenders\n",
        "!pip install -q --upgrade tensorflow-datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.preprocessing import OrdinalEncoder, StandardScaler , LabelEncoder\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        "\n",
        "from keras.models import Model, load_model, save_model\n",
        "#from keras.layers import Dense, Input, Dropout, Concatenate, Flatten, concatenate, Embedding, Reshape ,merge , dot\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras.callbacks import CSVLogger, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.compose import make_column_selector as selector\n",
        "import time\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import regularizers\n",
        "#import keras_tuner as kt\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "-osDg1nRs0Yn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pprint\n",
        "import tempfile\n",
        "\n",
        "from typing import Dict, Text\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "ra_GQK5Ds3nn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_recommenders as tfrs"
      ],
      "metadata": {
        "id": "EDSKtDrcs5yl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# file paths\n",
        "input1_path = '/content/user_features.csv'\n",
        "input2_path = '/content/items_pre.csv'\n",
        "input3_path = '/content/interactions_ranked.csv'"
      ],
      "metadata": {
        "id": "tI8wBEdxs6ZG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading datasets\n",
        "users_df = pd.read_csv(input1_path)\n",
        "songs_df = pd.read_csv(input2_path)\n",
        "interactions_df = pd.read_csv(input3_path)"
      ],
      "metadata": {
        "id": "nchZcm1ys-v8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing \n",
        "def user_preprocess(dataframe):\n",
        "    \n",
        "    dff =  dataframe.copy()\n",
        "    dff['MSISDN_VOICE'] = dff['MSISDN_VOICE'].astype('str')\n",
        " \n",
        "    cateogry_columns=dff.select_dtypes(include=['object']).columns.tolist()\n",
        "    integer_columns=dff.select_dtypes(include=['int64','float64']).columns.tolist()\n",
        "\n",
        "    for column in dff:\n",
        "        if dff[column].isnull().any():\n",
        "                if(column in cateogry_columns):\n",
        "                     dff[column]=dff[column].fillna(dff[column].mode()[0])\n",
        "                else:\n",
        "                     dff[column]=dff[column].fillna(dff[column].mode()[0])\n",
        "    \n",
        "    numerical_columns_selector = selector(dtype_exclude=object)\n",
        "    categorical_columns_selector = selector(dtype_include=object)\n",
        "\n",
        "    numerical_columns = numerical_columns_selector(dff)\n",
        "    categorical_columns = categorical_columns_selector(dff)\n",
        "\n",
        "\n",
        "    categorical_preprocessor = OrdinalEncoder()\n",
        "    numerical_preprocessor = StandardScaler()\n",
        " \n",
        "    preprocessor = ColumnTransformer([\n",
        "    ('ordinal-encoder', categorical_preprocessor, categorical_columns),\n",
        "    ('standard-scaler', numerical_preprocessor, numerical_columns)])\n",
        "    \n",
        "    data = preprocessor.fit_transform(dff)\n",
        "    data = pd.DataFrame(data , columns = users_df.columns)\n",
        "   \n",
        "    \n",
        "    return data\n",
        "\n",
        "def item_preprocess(dataframe):\n",
        "    \n",
        "    dff =  dataframe.copy()\n",
        "    dff['TONECODE'] = dff['TONECODE'].astype('str')\n",
        "    dff['LANGUAGE'] = dff['LANGUAGE'].astype('str')\n",
        "    dff['ARTIST']  = dff['ARTIST'].astype('str')\n",
        "    \n",
        "    cateogry_columns=dff.select_dtypes(include=['object']).columns.tolist()\n",
        "    integer_columns=dff.select_dtypes(include=['int64','float64']).columns.tolist()\n",
        "\n",
        "    for column in dff:\n",
        "        if dff[column].isnull().any():\n",
        "                if(column in cateogry_columns):\n",
        "                     dff[column]=dff[column].fillna(dff[column].mode()[0])\n",
        "                else:\n",
        "                     dff[column]=dff[column].fillna(dff[column].mode()[0])\n",
        "    \n",
        "    numerical_columns_selector = selector(dtype_exclude=object)\n",
        "    categorical_columns_selector = selector(dtype_include=object)\n",
        "\n",
        "    numerical_columns = numerical_columns_selector(dff)\n",
        "    categorical_columns = categorical_columns_selector(dff)\n",
        "\n",
        "\n",
        "    categorical_preprocessor = OrdinalEncoder()\n",
        "    numerical_preprocessor = StandardScaler()\n",
        " \n",
        "    preprocessor = ColumnTransformer([\n",
        "    ('ordinal-encoder', categorical_preprocessor, categorical_columns),\n",
        "    ('standard-scaler', numerical_preprocessor, numerical_columns)])\n",
        "    \n",
        "    data = preprocessor.fit_transform(dff)\n",
        "    data = pd.DataFrame(data , columns = songs_df.columns)\n",
        "   \n",
        "    \n",
        "    return data\n",
        "\n",
        "def interaction_preprocess(dataframe):\n",
        "    dff = dataframe.copy()\n",
        "    dff.drop(columns = ['RANKING' , 'NUM_OF_DAYS'] , axis = 1 , inplace = True)\n",
        "    \n",
        "    \n",
        "    dff['MSISDN']   = dff['MSISDN'].astype('str')\n",
        "    dff['TONECODE'] = dff['TONECODE'].astype('str')\n",
        "    \n",
        "    cateogry_columns=dff.select_dtypes(include=['object']).columns.tolist()\n",
        "    integer_columns=dff.select_dtypes(include=['int64','float64']).columns.tolist()\n",
        "\n",
        "    for column in dff:\n",
        "        if dff[column].isnull().any():\n",
        "                if(column in cateogry_columns):\n",
        "                     dff[column]=dff[column].fillna(dff[column].mode()[0])\n",
        "                else:\n",
        "                     dff[column]=dff[column].fillna(dff[column].mode()[0])\n",
        "    \n",
        "    numerical_columns_selector = selector(dtype_exclude=object)\n",
        "    categorical_columns_selector = selector(dtype_include=object)\n",
        "\n",
        "    numerical_columns = numerical_columns_selector(dff)\n",
        "    categorical_columns = categorical_columns_selector(dff)\n",
        "\n",
        "\n",
        "    categorical_preprocessor = OrdinalEncoder()\n",
        "    numerical_preprocessor = StandardScaler()\n",
        " \n",
        "    preprocessor = ColumnTransformer([\n",
        "    ('ordinal-encoder', categorical_preprocessor, categorical_columns),\n",
        "    ('standard-scaler', numerical_preprocessor, numerical_columns)])\n",
        "    \n",
        "    data = preprocessor.fit_transform(dff)\n",
        "    column_names = categorical_columns + numerical_columns\n",
        "    data = pd.DataFrame(data , columns = column_names)\n",
        "    data['RANKING'] = dataframe['RANKING']\n",
        "    \n",
        "    return data"
      ],
      "metadata": {
        "id": "cLq_fiRL36q0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "processed_song = item_preprocess(songs_df)\n",
        "processed_user = user_preprocess(users_df)\n",
        "processed_interactions = interaction_preprocess(interactions_df)"
      ],
      "metadata": {
        "id": "v8Y0zaDp3-Kc"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_test = processed_interactions.merge(processed_user , left_on=['MSISDN'] , right_on= ['MSISDN_VOICE'])\n",
        "df_train_test = df_train_test.merge(processed_song , on = 'TONECODE')"
      ],
      "metadata": {
        "id": "OUyeTu3ztEPh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_test = df_train_test.drop_duplicates()\n"
      ],
      "metadata": {
        "id": "mvTWbHIrtdOw"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_interactions.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibxuIodCLTuT",
        "outputId": "3b87ff6f-5f3d-4edc-b328-dd97ceeec8f2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 236656 entries, 0 to 236655\n",
            "Data columns (total 4 columns):\n",
            " #   Column            Non-Null Count   Dtype  \n",
            "---  ------            --------------   -----  \n",
            " 0   MSISDN            236656 non-null  float64\n",
            " 1   TONECODE          236656 non-null  float64\n",
            " 2   TRANSACTION_DATE  236656 non-null  float64\n",
            " 3   RANKING           236656 non-null  int64  \n",
            "dtypes: float64(3), int64(1)\n",
            "memory usage: 7.2 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_test.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSccoeyZwcBH",
        "outputId": "7d0a2098-2b5f-4120-cd6d-d97b641dc939"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 236496 entries, 0 to 240869\n",
            "Data columns (total 37 columns):\n",
            " #   Column                     Non-Null Count   Dtype  \n",
            "---  ------                     --------------   -----  \n",
            " 0   MSISDN                     236496 non-null  float64\n",
            " 1   TONECODE                   236496 non-null  float64\n",
            " 2   TRANSACTION_DATE           236496 non-null  float64\n",
            " 3   RANKING                    236496 non-null  int64  \n",
            " 4   MSISDN_VOICE               236496 non-null  float64\n",
            " 5   AGE                        236496 non-null  float64\n",
            " 6   CONTACT_GENDER             236496 non-null  float64\n",
            " 7   DISTRICT_CODE              236496 non-null  float64\n",
            " 8   PREFERRED_LANGUAGE         236496 non-null  float64\n",
            " 9   HSPA                       236496 non-null  float64\n",
            " 10  ENTERTAINMENT_MUSIC_LOVER  236496 non-null  float64\n",
            " 11  SOCIAL_MEDIA_USER          236496 non-null  float64\n",
            " 12  ENTERTAINMENT_MOVIE_LOVER  236496 non-null  float64\n",
            " 13  CYBER_GAMERS               236496 non-null  float64\n",
            " 14  PARENT                     236496 non-null  float64\n",
            " 15  PROFESSION                 236496 non-null  float64\n",
            " 16  RELIGION                   236496 non-null  float64\n",
            " 17  SPORTS_LOVER               236496 non-null  float64\n",
            " 18  VIDEO_WATCHER              236496 non-null  float64\n",
            " 19  TV_WATCHERS                236496 non-null  float64\n",
            " 20  TIKTOK_USER                236496 non-null  float64\n",
            " 21  EZCASH_USER                236496 non-null  float64\n",
            " 22  STARPOINT_USER             236496 non-null  float64\n",
            " 23  GENIE_USER                 236496 non-null  float64\n",
            " 24  PROMOTION_SEEKER           236496 non-null  float64\n",
            " 25  VIU_USER                   236496 non-null  float64\n",
            " 26  ARPU                       236496 non-null  float64\n",
            " 27  SONGNAME                   236496 non-null  float64\n",
            " 28  CHROMA_STFT                236496 non-null  float64\n",
            " 29  RMSE                       236496 non-null  float64\n",
            " 30  SPEC_CENT                  236496 non-null  float64\n",
            " 31  SPEC_BW                    236496 non-null  float64\n",
            " 32  ROLLOFF                    236496 non-null  float64\n",
            " 33  ZCR                        236496 non-null  float64\n",
            " 34  MFCC                       236496 non-null  float64\n",
            " 35  LANGUAGE                   236496 non-null  float64\n",
            " 36  ARTIST                     236496 non-null  float64\n",
            "dtypes: float64(36), int64(1)\n",
            "memory usage: 68.6 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_columns = users_df.columns\n",
        "item_columns  = songs_df.columns"
      ],
      "metadata": {
        "id": "hpVtpD5hysHp"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_user_features = len(user_columns)\n",
        "num_item_features = len(item_columns)\n"
      ],
      "metadata": {
        "id": "IK8jiD2rtjRA"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "item_train, item_test = train_test_split(df_train_test[item_columns], train_size=0.80, shuffle=True, random_state=1)\n",
        "user_train, user_test = train_test_split(df_train_test[user_columns], train_size=0.80, shuffle=True, random_state=1)\n",
        "y_train, y_test       = train_test_split(df_train_test[\"RANKING\"],    train_size=0.80, shuffle=True, random_state=1)\n",
        "print(f\"movie/item training data shape: {item_train.shape}\")\n",
        "print(f\"movie/item test data shape: {item_test.shape}\")"
      ],
      "metadata": {
        "id": "c4qRaw-xtk8K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42faef7d-8c0a-4123-f658-1edc7bee03ca"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "movie/item training data shape: (189196, 11)\n",
            "movie/item test data shape: (47300, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_outputs = 32\n",
        "tf.random.set_seed(1)\n",
        "user_NN = tf.keras.models.Sequential([\n",
        "    ### START CODE HERE ###     \n",
        "     tf.keras.layers.Dense(256 , activation = \"relu\"),\n",
        "      tf.keras.layers.Dense(128 , activation = \"relu\"),\n",
        "      tf.keras.layers.Dense(num_outputs)\n",
        "  \n",
        "  \n",
        "    ### END CODE HERE ###  \n",
        "])\n",
        "\n",
        "item_NN = tf.keras.models.Sequential([\n",
        "    ### START CODE HERE ###     \n",
        "      tf.keras.layers.Dense(256 , activation = \"relu\"),\n",
        "      tf.keras.layers.Dense(128 , activation = \"relu\"),\n",
        "      tf.keras.layers.Dense(num_outputs)\n",
        "  \n",
        "  \n",
        "    ### END CODE HERE ###  \n",
        "])\n",
        "\n",
        "# create the user input and point to the base network\n",
        "input_user = tf.keras.layers.Input(shape=(num_user_features))\n",
        "vu = user_NN(input_user)\n",
        "vu = tf.linalg.l2_normalize(vu, axis=1)\n",
        "\n",
        "# create the item input and point to the base network\n",
        "input_item = tf.keras.layers.Input(shape=(num_item_features))\n",
        "vm = item_NN(input_item)\n",
        "vm = tf.linalg.l2_normalize(vm, axis=1)\n",
        "\n",
        "# compute the dot product of the two vectors vu and vm\n",
        "output = tf.keras.layers.Dot(axes=1)([vu, vm])\n",
        "\n",
        "# specify the inputs and output of the model\n",
        "model = tf.keras.Model([input_user, input_item], output)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Czm1iHDSuQso",
        "outputId": "550194f2-eb4c-4392-8f6b-386169d49866"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 23)]         0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 11)]         0           []                               \n",
            "                                                                                                  \n",
            " sequential (Sequential)        (None, 32)           43168       ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " sequential_1 (Sequential)      (None, 32)           40096       ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " tf.math.l2_normalize (TFOpLamb  (None, 32)          0           ['sequential[0][0]']             \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.math.l2_normalize_1 (TFOpLa  (None, 32)          0           ['sequential_1[0][0]']           \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " dot (Dot)                      (None, 1)            0           ['tf.math.l2_normalize[0][0]',   \n",
            "                                                                  'tf.math.l2_normalize_1[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 83,264\n",
            "Trainable params: 83,264\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(1)\n",
        "cost_fn = tf.keras.losses.MeanSquaredError()\n",
        "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
        "model.compile(optimizer=opt,\n",
        "              loss=cost_fn)"
      ],
      "metadata": {
        "id": "GhPKWB9f05rr"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(1)\n",
        "model.fit([user_train, item_train], y_train, epochs=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaDMIdEM7YOL",
        "outputId": "aa3dcbcb-15a8-45fc-dc50-819da5da14df"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "5913/5913 [==============================] - 37s 6ms/step - loss: 20.7751\n",
            "Epoch 2/30\n",
            "5913/5913 [==============================] - 29s 5ms/step - loss: 20.7732\n",
            "Epoch 3/30\n",
            "5913/5913 [==============================] - 23s 4ms/step - loss: 20.7732\n",
            "Epoch 4/30\n",
            "5913/5913 [==============================] - 25s 4ms/step - loss: 20.7732\n",
            "Epoch 5/30\n",
            "5913/5913 [==============================] - 23s 4ms/step - loss: 20.7732\n",
            "Epoch 6/30\n",
            "5913/5913 [==============================] - 25s 4ms/step - loss: 20.7732\n",
            "Epoch 7/30\n",
            "5913/5913 [==============================] - 22s 4ms/step - loss: 20.7732\n",
            "Epoch 8/30\n",
            "5913/5913 [==============================] - 23s 4ms/step - loss: 20.7732\n",
            "Epoch 9/30\n",
            "5913/5913 [==============================] - 23s 4ms/step - loss: 20.7732\n",
            "Epoch 10/30\n",
            "5913/5913 [==============================] - 22s 4ms/step - loss: 20.7732\n",
            "Epoch 11/30\n",
            "5913/5913 [==============================] - 23s 4ms/step - loss: 20.7732\n",
            "Epoch 12/30\n",
            "5913/5913 [==============================] - 21s 4ms/step - loss: 20.7732\n",
            "Epoch 13/30\n",
            "5913/5913 [==============================] - 22s 4ms/step - loss: 20.7732\n",
            "Epoch 14/30\n",
            "5913/5913 [==============================] - 22s 4ms/step - loss: 20.7732\n",
            "Epoch 15/30\n",
            "5913/5913 [==============================] - 21s 4ms/step - loss: 20.7732\n",
            "Epoch 16/30\n",
            "5913/5913 [==============================] - 23s 4ms/step - loss: 20.7732\n",
            "Epoch 17/30\n",
            "5913/5913 [==============================] - 23s 4ms/step - loss: 20.7732\n",
            "Epoch 18/30\n",
            "5913/5913 [==============================] - 24s 4ms/step - loss: 20.7732\n",
            "Epoch 19/30\n",
            "5913/5913 [==============================] - 24s 4ms/step - loss: 20.7732\n",
            "Epoch 20/30\n",
            "5913/5913 [==============================] - 24s 4ms/step - loss: 20.7732\n",
            "Epoch 21/30\n",
            "5913/5913 [==============================] - 22s 4ms/step - loss: 20.7732\n",
            "Epoch 22/30\n",
            "5913/5913 [==============================] - 21s 4ms/step - loss: 20.7732\n",
            "Epoch 23/30\n",
            "5913/5913 [==============================] - 24s 4ms/step - loss: 20.7732\n",
            "Epoch 24/30\n",
            "5913/5913 [==============================] - 21s 4ms/step - loss: 20.7732\n",
            "Epoch 25/30\n",
            "5913/5913 [==============================] - 23s 4ms/step - loss: 20.7732\n",
            "Epoch 26/30\n",
            "5913/5913 [==============================] - 21s 4ms/step - loss: 20.7732\n",
            "Epoch 27/30\n",
            "5913/5913 [==============================] - 22s 4ms/step - loss: 20.7732\n",
            "Epoch 28/30\n",
            "5913/5913 [==============================] - 22s 4ms/step - loss: 20.7732\n",
            "Epoch 29/30\n",
            "5913/5913 [==============================] - 27s 4ms/step - loss: 20.7732\n",
            "Epoch 30/30\n",
            "5913/5913 [==============================] - 22s 4ms/step - loss: 20.7732\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f29918a1a60>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate([user_test, item_test], y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baZW5_MGCP6h",
        "outputId": "6dc07f39-ffbc-4d3c-feee-0a0bb57c36d6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1479/1479 [==============================] - 3s 2ms/step - loss: 21.0527\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21.052684783935547"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NqmtdPelNQSo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}